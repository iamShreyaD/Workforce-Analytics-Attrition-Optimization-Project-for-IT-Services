-Data audit

1. Data completeness
49653 records found in total.
There are no null values.
One placeholder found where terminationdate_key column should be null is filled with 1/1/1900.
Several column names need edits. some are in upper case, some in lower. Use upper() for all. probably make the names simpler. Remove column gender_full. change store_name to store_no.
2. Logical Consistency between fields
5718 records where employee status is Active but termination date is populated.
No records where employee status is Terminated but termination reason is missing.
No records where termination type present for an active employee.
No records where termination date missing or placeholder for terminated employees.
3. Data validity and timeline accuracy
24321 records where birth date occurring after hire date.
46192 records where termination date earlier than hire date 46192.
No records where future dates in historical records.
No records where year in record date not aligning with employee status year.
No records where age and length of service inconsistency exists.
4. Snapshot integrity
10 distinct employee records where same employee appearing multiple times in the same year.
No employee switches from Terminated → Active in later years.
No missing years in employee timelines.
5. Categorical data consistency
No records found where the gender represented as both M/F and Male/Female. So, gender_full column can be eliminated safely.
No spelling error in department names.
No mixed casing in status values.
6. Duplicate and uniqueness validation
5 records where same employee appearing multiple times for the same year.
No duplicate rows with identical attributes found.
7. Derived field accuracy
No records found where age is not matching birth date and record year.
No records of length of service not aligning with hire date.
8. Business rule alignment
No records where store employees classified as head office.
No records where termination reasons applied to active employees.
8237 records found where business unit mismatches with job titles.

-Data Cleaning

49653 records at the beginning of data cleaning.
Created a new table employee_clean and inserted the data from employee_raw to it.
Standardizing the names of columns. new columns names are employee_id, store_no, gender_short to gender, status_year, status, business_unit.
Dropped column gender_full.
I cannot use employee_clean further since I have tried updating terminationdate_key column numerous time in many ways. 
Thus, i decided to take pivot and I preserved raw HR snapshots, performed audit & validation in SQL, built a cleaned analytical layer via transformations, and modeled KPIs in Power BI.

-Transformations
Created a table called employee_analytics from employee_raw with these columns: 
EmployeeID, STATUS_YEAR, STATUS, BUSINESS_UNIT, department_name, job_title, city_name, store_name, gender_short AS gender, termination_date, hire_date, birth_date, age, length_of_service,
  termreason_desc, termtype_desc
Verified with the total count with the count of employee_raw.
Since there were database limitations to further process, I decided to move to power BI. I extracted employee_analytics.csv.

-HR_attrition_analytics
Created 3 columns: attrition_flag (status), age_band (age), tenure_band (length_of_service)
Created 6 measures: total_employees, active_employees, terminated_employees, attrition_rate, early_exit_percentage, avg_tenure
Created a table with years and the 6 measures to verify data.
https://github.com/iamShreyaD/Workforce-Analytics-Attrition-Optimization-Project-for-IT-Services/blob/main/Images/Screenshot%202026-01-05%20161535.png

To check for duplicated rows, I created 2 measures, one containing total rows of table and another containing summarized rows of table, employee_id and year.
There was difference of 5 rows.
In the powerquery editor, I removed duplicate rows by selecting employee_id and year column. This was followed by verifying number of rows again - 49648 records.
At the end, to extract employee_ml.csv, I selected all the records in power query editor after retrieving duplicates. Thus, I have 49653 records in employee_ml.csv containing columns such as 
employee_id, year, status, business_unit, department_name, job_title, city_name, store_no,	gender,	termination_date,	hire_date, birth_date, age, length_of_service, termreason_desc, termtype_desc.

-employee_attrition_prediction.ipynb
Loaded employee_ml.csv to ipynb
Verified data shape. Result: 49653 x 16
Data types are as follows:
employee_id           int64
year                  int64
status               object
business_unit        object
department_name      object
job_title            object
city_name            object
store_no              int64
gender               object
termination_date     object
hire_date            object
birth_date           object
age                   int64
length_of_service     int64
termreason_desc      object
termtype_desc        object
Checked for null count: termination_date count came up to 42450.
Dropped columns: termination_date, termreason_desc, termtype_desc
Created a column called attrition_flag where status = "TERMINATED", then 1 and status = "ACTIVE", then 0.
Created 2 lists: numerical_features = year, store_no, age, length_of_service, categorical_features = department_name, business_unit, job_title, gender, city_name.
assigned the column attrition_flag to target(variable).
Created model_df dataframe combining numerical_features, categorical_features and target.
Verified by model_df.head() and shape: 49653 x 10.
Counted records and calculated percentage of attrition_flag from model_df.
Created a summary with attrition_flag, count, percentage.
Counted the frequency of job titles.
Created rare_titles where job titles frequency is less than 0.01 and replace their names with 'Other'.
Verified the count of individual records of job titles with value_counts().
Since machine learning models don’t handle categorical variables directly, I applied one-hot encoding with a dropped reference category to prevent multicollinearity, especially for Logistic Regression.
Feature Engineering & ML Readiness (Phase B2):
Prepared an ML-ready dataset by selecting relevant numeric and categorical features.
Explicitly excluded identifiers and leakage-prone columns. 
Reduced categorical noise by grouping rare job titles (<1% frequency) into an “Other” category.
Model Explainability & Insights:
Interpreted model outputs to identify key drivers of employee attrition using logistic regression coefficients and random forest feature importance. 
Analyzed the impact of tenure, age, department, job role, and business unit on attrition risk. 
Translated model insights into actionable HR recommendations, enabling data-driven retention strategies and risk prioritization.
Machine learning models were built to predict employee attrition. 
Logistic Regression identified tenure (length_of_service), age, job role, and location as primary drivers, while Random Forest confirmed these factors and captured additional non-linear interactions. 
Both models achieved strong ROC-AUC (>0.88 for LR, >0.93 for RF) and balanced recall vs. precision. 
Insights suggest short-tenure employees, certain roles, and specific locations are high-risk groups for attrition. 
These results provide actionable HR intelligence for retention strategies.
Verification of results-
Logistic Regression

Top attrition drivers:

age (positive) → higher risk for older employees? Could be early-retirement / contract employees.

Certain cities like Valemount, White Rock → location-specific attrition.

Job title = Other → rare/less senior roles are at higher risk.

Year → newer records could indicate recent joiners are at higher risk.

Protective features:

length_of_service (negative) → tenure is stabilizing factor.

Certain departments (Investment, Executive) → low attrition risk.

Certain cities → location-specific stability.

This aligns logically with HR domain knowledge: short tenure → higher risk, senior roles → lower risk, geography matters. ✅

Random Forest

Top features:

age, length_of_service, year, store_no → consistent with LR.

Gender shows some signal (M/F) but much smaller.

Certain cities and departments contribute as expected.

Interpretation: Random Forest prioritizes same features but also captures non-linear interactions (e.g., store + city combinations). ✅

Consistency check: LR and RF highlight same top features → strengthens confidence in model insights. 

-Dashboard in power bi
1. Workforce & Attrition Insights
KPI Cards derived from power bi measures as follows:
a. Total Employees - 6284
b. Active Employees - 6138
c. Terminated Employees - 1485
d. attrition rate - 23.55%
e. early exit % - 11.15%
f. average tenure - 11.38























